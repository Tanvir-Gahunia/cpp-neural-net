# MNIST Neural Network 🚀  

This project is a custom neural network implemented in **C++** to classify handwritten digits from the MNIST dataset. No external ML libraries—just pure, raw code!  

---

## 📊 Features  
- **Multi-layer Neural Network** with customizable architecture  
- **Activation Functions:** ReLU and Sigmoid  
- **Cost Function:** Mean Squared Error (MSE) (Exploring Cross-Entropy Loss for future updates)  
- **He Initialization** for efficient weight distribution  
- **Mini-batch Gradient Descent** for faster training  

---

## 🧠 Architecture  
Input Layer: 784 neurons (28x28 pixels)

Hidden Layer 1: 128 neurons

Hidden Layer 2: 64 neurons

Output Layer: 10 neurons


---

## ⚙️ Build Instructions  
```bash
# Compile the project  
./build.sh  

# Run the executable  
./exec  
```
---

## 🔧 Future Improvements
- Implementing **Cross-Entropy** Loss
- Adding model **saving/loading** functionality
- Exploring learning rate scheduling

---

## 📚 Acknowledgments

This project is a personal learning journey into neural networks and machine learning concepts.




